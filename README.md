# Hybrid Photo Culling System 📸

A smart photo culling system that combines traditional computer vision with modern vision models for optimal accuracy and performance.

## Features ✨

- **Dual Processing Modes**:
  - **Accurate Mode** (default): Uses CLIP or Ollama vision model for 85-90% accuracy on focus detection
  - **Fast Mode**: Traditional CV for quick triage (200ms/image vs 1s/image)

- **Smart Caching**: Never reprocess the same file/mode combination
- **Batch Processing**: Vision model processes 8 images at once for efficiency  
- **Graceful Fallback**: Auto-falls back to fast mode if GPU/CLIP unavailable
- **RAW Support**: Handles NEF, CR2, ARW, and other RAW formats
- **Intelligent Decisions**: Categorizes photos as Keep, Delete, or Review
- **Metadata Integration**:
  - ON1 Photo RAW support with .on1 sidecar files (Main workflow)
  - Universal XMP metadata for Lightroom, Capture One, Bridge and more
- **Multiple Culling Tools**:
  - ON1-specific metadata integration (Primary method)
  - Universal metadata support for all photo apps  
  - Standard culling with CSV output


## Quick Start 🚀

1. **Install Dependencies**:
```bash
pip install -r requirements_photo.txt
```

2. **Basic Usage**:
```bash
# ON1 Photo RAW culling (primary workflow, preserves existing metadata)
python culler_on1.py /path/to/photos --cache-dir ~/.cache

# Fast mode for quick triage (ON1 workflow)
python culler_on1.py /path/to/photos --fast --workers 8

# Force CPU for vision model
python culler_on1.py /path/to/photos --force-cpu

# Universal metadata culling (works with Lightroom, Bridge, etc.)
python culler_universal.py /path/to/photos --cache-dir ~/.cache
```

3. **View Results**:
```bash
# Save detailed JSON results (universal approach)
python culler_universal.py /photos --output results.json

# Move files marked for deletion (ON1 approach)
python culler_on1.py /photos --move-deletes

# Move files marked for deletion (universal approach)
python culler_universal.py /photos --move-deletes
```

4. **Advanced Usage with Metadata**:
```bash
# ON1 Photo RAW culling (preserves existing metadata)
python culler_on1.py /photos --cache-dir ~/.cache

# Universal metadata culling (works with Lightroom, Bridge, etc.)
python culler_universal.py /photos --cache-dir ~/.cache

# Use Ollama instead of CLIP for vision analysis (ON1)
python culler_on1.py /photos --use-ollama

# Use specific Ollama model (ON1)
python culler_on1.py /photos --use-ollama --ollama-model llava:13b

# Use Ollama instead of CLIP for vision analysis (universal)
python culler_universal.py /photos --use-ollama

# Use specific Ollama model (universal)
python culler_universal.py /photos --use-ollama --ollama-model llava:13b
```

## Processing Modes 🔄

### Accurate Mode (Default)
- Uses OpenAI CLIP vision model
- ~1 second per image on GPU, ~3 seconds on CPU
- 85-90% accurate on focus detection
- Batch processes 8 images at once
- Best for final culling decisions

### Fast Mode (`--fast`)
- Traditional computer vision (OpenCV)
- ~200ms per image
- Good for catching obvious problems (very blurry, completely black/white)
- Parallel processing with multiple workers
- Best for initial triage of large collections

## Examples 📋

```bash
# Process wedding photos with ON1 metadata (primary workflow)
python culler_on1.py ~/Photos/Wedding2024 --cache-dir ~/.cache

# Quick triage of 10,000 photos with ON1 workflow
python culler_on1.py ~/Photos/Massive_Collection --fast --workers 8

# Process only RAW files with ON1 workflow  
python culler_on1.py ~/Photos --extensions nef,cr2,arw

# Conservative CPU-only processing with ON1
python culler_on1.py ~/Photos --force-cpu --verbose

# Universal metadata approach (works with Lightroom, Bridge)
python culler_universal.py ~/Photos/Wedding2024 --cache-dir ~/.cache
```

## Configuration Options ⚙️

| Option | Default | Description |
|--------|---------|-------------|
| `--fast` | False | Use fast CV mode |
| `--cache-dir` | None | Cache directory for thumbnails/results |
| `--workers` | 4 | Parallel workers (fast mode only) |
| `--batch-size` | 8 | Batch size for vision model |
| `--force-cpu` | False | Force CPU even if GPU available |
| `--move-deletes` | False | Move deletion candidates to _culled_deletes/ |
| `--extensions` | nef,cr2,arw,jpg,jpeg | File extensions to process |
| `--output` | None | Save results to JSON file |
| `--use-ollama` | False | Use Ollama vision model instead of CLIP |
| `--ollama-model` | `llava:7b` | Which Ollama model to use |

## Decision Logic 🤔

The system evaluates three key metrics:

1. **Blur Score** (0-1): Higher = sharper focus
2. **Exposure Score** (0-1): Higher = better exposed  
3. **Composition Score** (0-1): Higher = more interesting

### Decision Thresholds:
- **Delete**: High confidence (>0.7) in critical issues (blur <0.3, exposure <0.4)
- **Review**: Medium confidence or multiple minor issues
- **Keep**: Good overall quality or low confidence in issues

## Performance Benchmarks ⚡

| Mode | Hardware | Speed | Accuracy | Best For |
|------|----------|--------|----------|----------|
| Fast | CPU | 200ms/img | 70% | Initial triage |
| Accurate | GPU | 1000ms/img | 90% | Final decisions |
| Accurate | CPU | 3000ms/img | 90% | High accuracy |

*Benchmarks on 24MP RAW files*

## File Structure 📁

```
ac_controller/
├── models.py              # Data structures 
├── analyzer.py            # Hybrid CV + Vision analysis
├── extractor.py           # RAW thumbnail extraction  
├── decision.py            # Culling decision logic
├── batch.py              # Batch processing with caching
├── culler_on1.py         # ON1 Photo RAW culling
├── culler_universal.py   # Universal metadata culling  
├── requirements_photo.txt # Python dependencies
└── test_on1_xmp.py       # System tests
```

## Dependencies 📦

### Required:
- **Pillow**: Image processing
- **NumPy**: Numerical operations  
- **OpenCV**: Computer vision
- **Click**: CLI framework

### Optional:
- **PyTorch + CLIP**: Vision model (for accurate mode)
- **rawpy**: RAW file processing
- **CUDA**: GPU acceleration

## Caching System 💾

The system intelligently caches:
- **Thumbnails**: Extracted from RAW files (prevents re-extraction)
- **Analysis Results**: Per file + mode combination  
- **Cache Keys**: Based on filename, size, modification time

Cache locations:
- Thumbnails: `{cache_dir}/thumbnails/`
- Results: `{cache_dir}/cull_results.json`

## Output Examples 📊

### Console Output:
```
==================================================
CULLING COMPLETE - ACCURATE MODE  
==================================================
Keep:    847 files
Delete:   23 files
Review:   15 files

Top deletion candidates:
  IMG_1234.NEF: blurry, poor exposure (conf: 0.89)
  IMG_5678.CR2: blurry (conf: 0.82)
  IMG_9012.ARW: poor exposure (conf: 0.76)

Processing stats:
  Average: 1250ms per image
  Total time: 18.2 minutes
```

### JSON Output:
```json
{
  "mode": "accurate",
  "results": {
    "Delete": [
      {
        "file": "/photos/IMG_1234.NEF",
        "confidence": 0.89,
        "issues": ["blurry", "poor exposure"],
        "processing_ms": 1205,
        "metrics": {
          "blur": 0.12,
          "exposure": 0.31,
          "composition": 0.67,
          "overall": 0.25
        }
      }
    ]
  }
}
```

## Troubleshooting 🔧

### Common Issues:

**"No module named 'torch'"**
- Install vision model dependencies: `pip install torch clip-by-openai`
- Or use fast mode: `--fast`

**"Failed to load CLIP"**
- Check GPU memory availability
- Try CPU mode: `--force-cpu`  
- Fall back to fast mode automatically

**"No RAW files processed"**
- Install rawpy: `pip install rawpy`
- Check file extensions: `--extensions nef,cr2,arw`

**Slow processing**
- Use fast mode for triage: `--fast`
- Reduce batch size: `--batch-size 4`
- Enable caching: `--cache-dir ~/.cache`

### Ollama Issues:

**"Cannot connect to Ollama"**
- Make sure Ollama is running: `ollama serve`
- Check if it's accessible: `curl http://localhost:11434/api/tags`

**"Model not found"**
- List available models: `ollama list`
- Pull the model if missing: `ollama pull llava:7b`

**"Ollama query failed"**
- Check Ollama logs: `ollama logs`
- Restart Ollama service
- Try a different model


## Advanced Usage 🎯

### Custom Decision Thresholds:
Modify `decision.py`:
```python
CullingDecisionEngine(
    blur_threshold=0.4,        # Stricter blur detection
    exposure_threshold=0.3,    # More exposure tolerance
    delete_confidence_threshold=0.8  # Higher confidence needed
)
```

### Integration with Other Tools:
```python
from ac_controller import BatchCuller, ProcessingMode

culler = BatchCuller(mode=ProcessingMode.ACCURATE)
results = culler.process_folder_batch(Path("/photos"))

for result in results['Delete']:
    print(f"Delete: {result.filepath} ({result.confidence:.2f})")
```

### ON1 Workflow Best Practices:
When using `culler_on1.py`:

- **Process in ON1 Photo RAW** after running culler to see metadata keywords
- Use `--move-deletes` to automatically move deletion candidates to `_culled_deletes/`
- Search for keywords like `PhotoCuller:Delete` in ON1 to identify candidates
- Review high-confidence deletion candidates (confidence > 0.7) before deleting

### Universal Workflow Best Practices:
When using `culler_universal.py`:

- Use with any photo app (Lightroom, Bridge, Capture One)
- Metadata is stored in `.xmp` sidecar files
- Preserve existing ratings, keywords and descriptions  
- Search for metadata like `PhotoCuller:Delete` in your photo app

## License 📄

MIT License - Feel free to use and modify for your photo workflow!

---

**Pro Tip**: Start with fast mode on large collections, then use accurate mode on the "Review" category for final decisions. This hybrid approach gives you the best of both worlds! 🎯

## Repository Status 🔍

The repository is designed to be public and does not contain any personal information. All paths in example code have been updated for general use.

Please review the following before making this repository public:

1. **Test Files**: Remove any personal test data from `test/` directory
2. **Configuration files**: Ensure no private information in `.env` or config files (none currently exist)
3. **API Keys**: This tool does not use any external API keys
4. **User Paths**: All user-specific paths in example code have been replaced with generic references

You can safely make this repository public as it contains only the core tool functionality.
